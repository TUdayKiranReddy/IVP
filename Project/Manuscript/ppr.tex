% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2022}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Team 4 - Preliminary Project Report}

\author{Tadipatri Uday Kiran Reddy\\
{\tt\small ee19btech11038@iith.ac.in}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Sahukari Chaitanya Varun\\
{\tt\small ee19btech11040@iith.ac.in}
\and
L. Pranay Kumar Reddy\\
{\tt\small ai19btech11010@iith.ac.in}
}
\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
With the evolution of high resolution digital cameras, snapshots have become a most common way to record and share visual data and experiences taken through mobile phones and tablets. But as humans, it is difficult to keep a stiff hold while capturing image, especially, when image is to be captured on move introducing blur. Though there lot of external tools for frame stabilization such as gimbal, mounting it on can be difficult at times. Hence, we propose this paper to solve this problem by processing the image with the aid of gyroscope sensed data which is attached with the camera device, helping to deblur the image. We aim to implement this deblurring with the help of deep convolution nets and extrapolate it with GAN's to give better quality and faster output than compared to traditional CNN's. With faster computation capabilities, we can extend this work to stabilise the video feed with lower frame rates.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:intro}
%Introduce the problem you are working on. This section should give a general introduction motivation for the problem. You can also describe the applications of your problem here. 
%
%Please number all of your sections and displayed equations as in these examples:
%\begin{equation}
%  E = m\cdot c^2
%  \label{eq:important}
%\end{equation}
%and
%\begin{equation}
%  v = a\cdot t.
%  \label{eq:also-important}
%\end{equation}
Most of the times, our desired scenes are in always in motion, capturing this in camera would introduce a fuzzy noise which is known as motion blur. This affect is also very severe in Autonoumus vehichle which utilise sophosticated visual SLAM algorithms on live feed coming from camera or LIDAR sensors which are in motion. Here the motion blur would supress the important features needed to be obtained from the video feed. Even with state-of-the-art technology of camera manufacturing, motion blur affect is not being improved while the resolution of the cameras are getting better and better.\\

Mechanically stabilising the sensor like camera or LIDAR is very hard, so we have to use rigourus algorithms to process the image and many \textbf{recent works} like {} came up with both linear and non-linear models to deblur the image but the processed images are having still some blur and implementation of such sophosticated algorithm in edge devices like mobile phones, DSLR cameras, etc is computationally infeasible. These works leave the fact behind that these motion blurs are caused due to relative motion between scene and camera. As all the mordern mobile phones and camera are equipped with Interial Measurement Units(\textit{IMU}), these actually measure velocity, acceleration, we can exploit this sensor data to deblur the images than only using raw image only as data. These \textbf{works} actually can up with system to exploit gyroscope sensor data, here they use Convonutaional Neural Network(CNN) with encoder and decoder framework, but these demand high computational power.\\

In this work we propose a framework which deblurres images with blurred image and gyroscope sensor data, with help of deep-CNN and extrapolate it with Generative Adveriserial Network(\textit{GAN}) to enchance the quality and faster output of deblurred image.\\
The below are the main contribuition of this paper.
\begin{enumerate}
	\item We propose a framework known as Motion blur Correction with Gyroscope using Generative Adverserial Networks(\textit{MCG-GAN})
	\item We use MCG-GAN for deblurring images and show the improvement with existing state-of-art-works.
\end{enumerate}
The rest of the paper is organised as follows - We discuss the detailed problem statement in Section 2. We provide literature review in Section 3 which describes the related works and mentions important results which are going to be used in proposed framework. In section 4, we show results of recent works on deblurring. Finally, in section 5, We cite the references from we have used or described the paper.
%------------------------------------------------------------------------
\section{Problem Statement}
\label{sec:problem}
The problem statement concisely is image deblurring aided by gyroscopic sensing implemented through GAN's, building upon the deep neural net solution. Though the blur introduced can be from relative motion between the camera and picturing object itself, we focus only on deblurring image due to the relative movement of the camera device.\\
The paper DeBlurGAN has already produced a benchmark result in finding the blur and rectifying it, but assumes the blur to be space invariant, i.e, performs blind deblurrring over the whole image. We can at first estimate a spatially variant motion field and blur kernels from a single image using deep networks, thereafter perform non-blind deconvolution. But often, this process requires input of multiple images which might not always be available. We here focus on single image deblurring approach. \\

From the gyroscopic measurements, the rotation can be estimated as
\begin{equation}
    \frac{d \textbf{q(t)}}{dt} = \frac{1}{2}\textbf{q(t)} \bigodot \omega(t), \textbf{q(t1)=1}
\end{equation}
where $\omega$(t) is the 3-dimensional gyroscope measurement and $\bigodot$ denotes the quaternion product. The initial condition is given at the starting time of exposure t1 and the solution is computed at the end time of exposure t2.
The motion blur caused by translation will depend on the scene depth, which is difficult to estimate from a single image and hence take these limitations into account when generating training data. Consider $\textbf{R(t)}$ and $\textbf{t}$(t) as rotation and translation of camera. Assuming the scene depth to be a constant $\textbf{d}$ , the motion of camera can be modeled as planar homograph as :
\begin{equation}
    \textbf{H(t)} = \textbf{K[R}(t) - \frac{\textbf{t}(t)\textbf{n}^{T}}{d}\textbf{]K}^{-1}
\end{equation}
where K is the intrinsic camera matrix obtained via calibration. By taking the translation to be zero, this simplifies to 
\begin{equation}
    \textbf{H(t)} = \textbf{KR}(t)\textbf{K}^{-1}
\end{equation}
By this we can compute the blur vector for every pixel, which gives us the blur map of the image.
\section{Literature Review}
\label{sec:literature}
\subsection{Motion blur}
This is a phenomenon observed in images taken when there is relative motion between camera and the scene, these are the artifacts observes in most common camera which are mostly rolling shutter cameras. Many of the recent works model the motion blur as Linear Space invariant system as follows.
\begin{equation}
I_{\textbf{b}} = \textbf{h}*I + \textbf{n}
\end{equation}
Where $I_{\textbf{b}}$ is Blurred image, \textbf{h} is kernal which models the motion blur more ofently so know as Point Space Function(\textit{PSF}), I is actual unblurred image and finally \textbf{n} is noise added while capturing the snap.
\subsection{DeepGyro}
The deblurring is based on fully-convolutional neural network which aims to produce a shar image given blurred image and gyro-based blur field. The netwrok architecture is similar to encoder-decoder network, where the input network consists of blurred RGB image and a gyro-based blur field which pass through series of convolutional and downsampling layers until the lowest resolution is reached. After the bottleneck, this low resolution image is expanded back into a full resolution image with help of upsampling layers. Skip connections are used to allow information sharing between encoder and decoder.\\
For training of data, the blurred and sharp images with gyro-based blur fields are produced by taking the visual-inertial dataset which consists of various types camera motion resulting in different blur fields. The blur fields are themselves further distorted to exact and noisy blur fields for training a robust model. The paper states of utilizing nearly 100k images and was evaluated on both synthetically and naturally blurred images.
\\

In regard to the current paper we are working on, this refered paper serves as model for extracting the gyro data and also  help in generating the datasets required for training and testing the model. This model is embedded in initial stages of our model which is then build further by GANs.
\section{Preliminary Results}
\label{sec:prelim_results}
This is an optional section. This could include any results you have been able to replicate from the literature as well as any preliminary results that you want to report.

%-------------------------------------------------------------------------
\section{References}
List all the references you have read.

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
