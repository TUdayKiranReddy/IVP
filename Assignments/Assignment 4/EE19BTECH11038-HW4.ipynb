{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ac2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03faad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(X, Y, learning_rate=0.05, validation_split=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.X_train, self.X_valid, self.Y_train, self.Y_valid = None\n",
    "        self.lr = learning_rate\n",
    "        self.validation_split = validation_split\n",
    "        self.W1, self.W2, self.b1, self.b2, self.z1, self.z2, self.A1, self.A2 = None\n",
    "        self.dW1, self.dW2, self.db1, self.db2, self.dz1, self.dz2 = None\n",
    "    \n",
    "    def split_samples(self):\n",
    "        x = np.random.shuffle(self.X)\n",
    "        y = np.random.shuffle(self.Y)\n",
    "        vs = 0\n",
    "        m = self.X.shape[1]\n",
    "        if validation_split is not None:\n",
    "            vs = int(validation_split*m)\n",
    "        self.X_train = x[0:(m-vs)]\n",
    "        self.Y_train = y[0:(m-vs)]\n",
    "        self.X_valid = x[(m-vs):]\n",
    "        self.Y_valid = y[(m-vs):]\n",
    "        \n",
    "        \n",
    "    def initialise_params(self):\n",
    "        self.W1 = np.random.randn((2, 2))\n",
    "        self.b1 = np.random.randn((2, 1))\n",
    "        \n",
    "        self.W2 = np.random.randn((1, 2))\n",
    "        self.b2 = np.random.randn()\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1/(1 + np.exp(-1*x))\n",
    "        \n",
    "    def forward_prop(self, X):\n",
    "        self.z1 = self.W1@X + self.b1\n",
    "        self.A1 = sigmoid(self.z1)\n",
    "        \n",
    "        self.z2 = self.W2@self.A1 + self.b2\n",
    "        self.A2 = sigmoid(self.z2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        z1 = self.W1@X + self.b1\n",
    "        A1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = self.W2@A1 + self.b2\n",
    "        A2 = sigmoid(z2)\n",
    "        return A2\n",
    "    \n",
    "    def train_loss(self, Y):\n",
    "        return np.sum(np.power(self.Y_train - self.A2, 2))\n",
    "    \n",
    "    def valid_loss(self, X, Y):\n",
    "        Y_hat = self.predict(X)\n",
    "        return np.sum(np.power(Y - Y_hat, 2))\n",
    "    \n",
    "    def back_prop(self, X, Y):\n",
    "        self.dz2 = self.A2*(1 - self.A2) * 2*(self.A2 - Y)\n",
    "        self.dW2 = self.dz2 @ self.A1.T\n",
    "        self.db2 = np.sum(self.dz2, axis=1, keep_dim=True)\n",
    "        \n",
    "        self.dz1 = (self.W2.T @ self.dz2) * (self.A1*(1 - self.A1))\n",
    "        self.dW1 = self.dz1 @ X.T\n",
    "        self.db1 = np.sum(self.dz1, axis=1, keep_dim=True)\n",
    "    \n",
    "    def update_params(self):\n",
    "        self.W1 -= self.lr * self.dW1\n",
    "        self.W2 -= self.lr * self.dW2\n",
    "        self.b1 -= self.lr * self.db1\n",
    "        self.b2 -= self.lr * self.db2\n",
    "    \n",
    "    def train(self, epochs, mini_batch_size=1):\n",
    "        \n",
    "        training_loss = np.zeros((1, epochs))\n",
    "        validation_loss = np.zeros((1, epochs))\n",
    "        \n",
    "        N_mini_batch_size = int(self.X_train.shape[1] / mini_batch_size)\n",
    "        \n",
    "        self.initialise_params()\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            for j in range(N_mini_batch_size-1):\n",
    "                X = self.X_train[:, (j-1)*N_mini_batch_size : j*N_mini_batch_size]\n",
    "                Y = self.Y_train[:, (j-1)*N_mini_batch_size : j*N_mini_batch_size]\n",
    "                \n",
    "                self.forward_prop(X)\n",
    "                \n",
    "                training_loss[0, i] += (self.train_loss(Y))\n",
    "                validation_loss[0, i] += (self.valid_loss(self.X_valid, self.Y_valid))\n",
    "                \n",
    "                self.back_prop(X, Y)\n",
    "                \n",
    "                self.update_params()\n",
    "                \n",
    "            X = self.X_train[:, (-1*N_mini_batch_size) :]\n",
    "            Y = self.Y_train[:, (-1*N_mini_batch_size) :]\n",
    "\n",
    "            self.forward_prop(X)\n",
    "\n",
    "            training_loss[0, i] += (self.train_loss(Y))\n",
    "            validation_loss[0, i] += (self.valid_loss(self.X_valid, self.Y_valid))\n",
    "\n",
    "            self.back_prop(X, Y)\n",
    "\n",
    "            self.update_params()  \n",
    "            \n",
    "            print(\"Epoch {} :- Training Loss is {}, Validation Loss is {}\".format(i+1, training_loss[0, i], validation_loss[0, i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
